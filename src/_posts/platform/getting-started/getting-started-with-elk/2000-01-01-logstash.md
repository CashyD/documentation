---
title: Logstash
modified_at: 2024-06-21 12:00:00
tags: elk tutorial logstash elasticsearch kibana log
index: 2
---

## Deploying

### Using the Command Line

We maintain a repository called [logstash-scalingo](https://github.com/Scalingo/logstash-scalingo)
on GitHub to help you deploy Logstash on Scalingo. Here are the few steps you
will have to follow:

1. Clone our repository:

   ```bash
   git clone https://github.com/Scalingo/logstash-scalingo
   cd logstash-scalingo
   ```

2. Create the application on Scalingo:

   ```bash
   scalingo create my-logstash
   ```

   Notice that our Command Line automatically detects the git repository, and
   adds a git remote to Scalingo:

   ```bash
   git remote -v

   origin   https://github.com/Scalingo/logstash-scalingo (fetch)
   origin   https://github.com/Scalingo/logstash-scalingo (push)
   scalingo git@ssh.osc-fr1.scalingo.com:my-logstash.git (fetch)
   scalingo git@ssh.osc-fr1.scalingo.com:my-logstash.git (push)
   ```

3. Scale the container to an L size:

   ```
   scalingo --app my-logstash scale web:1:L
   ```

4. Attach the Elasticsearch addon:

   ```bash
   scalingo --app my-logstash addons-add elasticsearch elasticsearch-sandbox
   ```

5. Edit the `logstash.conf` file to change the index name of the Elasticsearch
   output. The goal is to make it fit semantically to the data being ingested:

   ```
   output {
     elasticsearch {
       [...]
       # OLD
       index => "change-me-%{+YYYY.MM.dd}"
       # NEW
       index => "unicorns-%{+YYYY.MM.dd}"
     }
   }
   ```

   Don't forget to commit your changes:

   ```bash
   git add logstash.conf
   git commit -m "Update the index name"
   ```

6. Create a few environment variables to protect your Logstash instance via 
   HTTP basic auth (not everyone should be able to send data to your instance!):

   ```bash
   scalingo --app my-logstash env-set USER=logstash-username
   scalingo --app my-logstash env-set PASSWORD=logstash-password
   ```

7. Everything's ready, deploy to Scalingo:

   ```bash
   git push scalingo master
   ```

### Using the Terraform Provider

{% note%}
The following code blocks are given as examples.\
You will have to adjust some values to suit your needs.
{% endnote %}

1. Start by forking our [Logstash repository](https://github.com/Scalingo/logstash-scalingo)

2. Place the following block in your Terraform file to create the app:

   ```terraform
   resource "scalingo_app" "my-logstash" {
     name        = "my-logstash"
     force_https = true

     environment = {
       USER     = "<logstash-username>"
       PASSWORD = "<logstash-password>"
     }
   }
   ```

3. Link the app to your forked repository:

   ```terraform
   data "scalingo_scm_integration" "github" {
     scm_type = "github"
   }

   resource "scalingo_scm_repo_link" "default" {
     auth_integration_uuid = data.scalingo_scm_integration.github.id
     app                   = scalingo_app.my-logstash.id
     source                = "https://github.com/<username>/logstash-scalingo"
     branch                = "master"
   }
   ```

4. Create a Sandbox ElasticSearch addon and attach it to your app:

   ```terraform
   resource "scalingo_addon" "my-logstash-elasticsearch" {
     app         = scalingo_app.my-logstash.id
     provider_id = "elasticsearch"
     plan        = "sandbox"
   }
   ```

5. (optional) Instruct the platform to run the `web` process type in a single
   L container:

   ```terraform
   resource "scalingo_container_type" "web" {
     app    = scalingo_app.my-logstash.id
     name   = "web"
     size   = "L"
     amount = 1
   }
   ```

6. Edit the `logstash.conf` file to change the index name of the Elasticsearch
   output. The goal is to make it fit semantically to the data being ingested:

   ```
   output {
     elasticsearch {
       [...]
       # OLD
       index => "change-me-%{+YYYY.MM.dd}"
       # NEW
       index => "unicorns-%{+YYYY.MM.dd}"
     }
   }
   ```

   Don't forget to commit your changes:

   ```bash
   git add logstash.conf
   git commit -m "Update the index name"
   git push
   ```

7. Run `terraform plan` and check if the result looks good
8. If so, run `terraform apply`
9. Once Terraform is done, your Logstash instance is provisioned and ready to
   be deployed. This requires an extra manual step:

   1. Head to [your dashboard](https://dashboard.scalingo.com/apps/)
   2. Click on your Logstash application
   3. Click on the **Deploy** tab
   4. Click on **Manual deployment** in the left menu
   5. Click the **Trigger deployment** button
   6. After a few seconds, your Logstash instance is finally up and running!


## Testing

1. Once your Logstash is up and running, you can try to send some data to it:

   ```bash
   curl --request POST 'https://<logstash-username>:<logstash-password>@my-logstash.osc-fr1.scalingo.io?name=whatever' --data 'Hello World!'
   ok
   ```

2. Check the indices that are stored in the Elasticsearch database:

   ```bash
   scalingo --app my-logstash run bash

   > curl $SCALINGO_ELASTICSEARCH_URL/_cat/indices
   yellow open unicorns-2024.06.04 _0XNpJKzQc2kjhTyxf4DnQ 5 1 1 0 6.6kb 6.6kb
   ```

3. Logstash has created the `unicorns` index which can now be requested:

   ```bash
   > curl $SCALINGO_ELASTICSEARCH_URL/unicorns-2024.06.04/_search | json_pp
   {
      "_shards" : {
        // [...]
      },
      // [...]
      "hits" : {
        "total" : 1,
        "max_score" : 1,
        "hits" : [
          {
            "_type" : "logs",
            "_score" : 1,
            "_source" : {
               "name" : "whatever",
               "message" : "Hello World!",
               "url" : "?name=whatever",
               "@timestamp" : "2024-06-04T11:57:03.155Z"
               // [...]
            },
            // [...]
          }
        ]
      }
    }
    ```

   The result of the above search contains a document having a field
   `name` set to `whatever` and a field `message` set to `Hello World!`.


## Send your application logs to your own ELK stack

One of the multiple usages of the ELK stack is log parsing, storing and
exploration. If you've set up your ELK stack for this, we have a feature called
**log drains** that will automatically send every log line generated by an
application to an ELK stack. Here is [how to add a log drain]({% post_url
platform/app/2000-01-01-log-drain %}) to your application.

When using this configuration, the application name and container index will be
passed in the http query and the message will be in the request body. To parse
this and create meaningful index, you can use the following Logstash configuration (if
your logs are JSON formatted):

```
input {
  http {
    port => "${PORT}"
    user => "${USER}"
    password => "${PASSWORD}"
  }
}

filter {
  grok {
    match => [ "[headers][request_path]", "%{URIPARAM:url}" ]
    remove_field => ["headers"]
  }

  kv {
    source => "url"
    field_split => "&"
    trim_key => "?"
  }

  mutate {
    rename => {
      "appname" => "source"
      "hostname" => "container"
    }
    replace => {
      "host" => "%{source}-%{container}"
    }
  }

  json {
    source => "message"
    target => "msg"
  }
}

output {
  elasticsearch {
    hosts => "${ELASTICSEARCH_HOST}"
    user => "${ELASTICSEARCH_USER}"
    password => "${ELASTICSEARCH_PASSWORD}"
    index => "unicorns-%{+YYYY.MM.dd}"
  }
}
```

## Updating

By default, Scalingo deploys a version of Logstash that is compatible with the
Elasticsearch instances we provide.

Consequently, updating Logstash only consists in triggering a new deployment of
your instance. To do so, create an empty commit and push it to Scalingo:

```bash
git commit --allow-empty -m "Update Logstash"
git push scalingo master
```

{% note %}
* Scalingo provides a version of Logstash that is compatible with the latest
  Elasticsearch 7.10.x version. Our repository won't be updated as long as we
  are [stuck with this constraint]({% post_url platform/getting-started/getting-started-with-elk/2000-01-01-overview %}).
* However, you can use the dedicated environment variable [see below](#environment)
  to deploy a specific version of your choice.
{% endnote %}


## Customizing

### Configuring

The repository we provide help deploy your Logstash instance comes with a
directory named `config`. All the files contained in this directory are copied
in the Logstash configuration directory at runtime, allowing you to precisely
customize your instance.

For example, if you'd want to modify the logging behavior of Logstash, you
could edit the `config/log4j2.yml` file.

### Environment

The following environment variable(s) can be leveraged to customize your
deployment:

- **`USER`**\
  Logstash administrator account name.\
  **mandatory**

- **`PASSWORD`**\
  Logstash administrator password.\
  **mandatory**

- **`LOGSTASH_PLUGINS`**\
  Comma separated [list of plugins](https://github.com/logstash-plugins) to
  install.\
  Defaults to not being set.

- **`LOGSTASH_VERSION`**\
  Version of Logstash to deploy.\
  Defaults to `6.8.21`
